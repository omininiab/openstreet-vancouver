{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import pprint as pp\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import cerberus\n",
    "import schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "osm_path = \"vancouver_canada.osm\"\n",
    "\n",
    "nodes_path = \"nodes.csv\"\n",
    "node_tags_path = \"node_tags.csv\"\n",
    "ways_path = \"ways.csv\"\n",
    "way_nodes_path = \"way_nodes.csv\"\n",
    "way_tags_path = \"way_tags.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_tags(filename):\n",
    "    \"\"\"\n",
    "    This function uses iterative parsing to process the map file and find out \n",
    "    not only what tags are there, but also how many, to get the\n",
    "    feeling on how much of which data you can expect to have in the map.\n",
    "    It should return a dictionary with the tag name as the key and number of \n",
    "    times this tag can be encountered in the map as value.\n",
    "    \"\"\"\n",
    "    tags = {}\n",
    "    for event, element in ET.iterparse(filename):\n",
    "        if element.tag not in tags:\n",
    "            tags[element.tag] = 1\n",
    "        else:\n",
    "            tags[element.tag] += 1\n",
    "        \n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def key_type(element, keys):\n",
    "    \"\"\"\n",
    "    This is a helper function for comparing tags to potential problems and increments \n",
    "    the count of the problem in the dictionary that keeps track of 4 of these problems.\n",
    "    four tag categories in a dictionary:\n",
    "    \"lower\", for tags that contain only lowercase letters and are valid,\n",
    "    \"lower_colon\", for otherwise valid tags with a colon in their names,\n",
    "    \"problemchars\", for tags with problematic characters, and\n",
    "    \"other\", for other tags that do not fall into the other three categories.\n",
    "    \"\"\"\n",
    "    if element.tag == \"tag\":\n",
    "        for tag in element.iter(\"tag\"):\n",
    "            street = tag.attrib[\"k\"]\n",
    "            if lower.search(street):\n",
    "                keys[\"lower\"] += 1\n",
    "            elif lower_colon.search(street):\n",
    "                keys[\"lower_colon\"] += 1\n",
    "            elif problemchars.search(street):\n",
    "                keys[\"problemchars\"] += 1\n",
    "            else:\n",
    "                keys[\"other\"] += 1\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_keys(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_users(element):\n",
    "    users = set()\n",
    "    index = \"uid\"\n",
    "    user_tags = [\"way\", \"relation\"]\n",
    "\n",
    "    tag = element.tag\n",
    "    if tag == \"node\":\n",
    "        try:\n",
    "            users.add(element.attrib[index])\n",
    "        except:\n",
    "            users = users\n",
    "    elif tag in user_tags:\n",
    "        for member in element.iter(tag):\n",
    "            try:\n",
    "                if member.attrib[\"uid\"]:\n",
    "                    users.add(member.attrib[index])\n",
    "            except:\n",
    "                users = users\n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_users(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        for user in get_users(element):\n",
    "            users.add(user)\n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expected = [\"Street\", \"Alley\", \"Avenue\", \"Boulevard\", \"Crescent\", \"Drive\", \n",
    "            \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \"Mall\", \"Broadway\",\n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Connector\", \"Walk\", \"Way\", \"Highway\", \n",
    "            \"Mews\", \"Kingsway\", \"Greenway\", \"Seawall\", \"South\", \"Terminal\"]\n",
    "\n",
    "\n",
    "mapping = {\"St\": \"Street\", \"St.\": \"Street\", \"street\": \"Street\", \"Steet\": \"Street\", \n",
    "           \"Ave\": \"Avenue\", \"Venue\": \"Avenue\", \n",
    "           \"Blvd\": \"Boulevard\", \"BLVD\": \"Boulevard\", \n",
    "           \"Esplanade\": \"Esplanade Avenue\", \n",
    "           \"Rd.\": \"Road\", \n",
    "           \"Jervis\": \"Jervis Street\", \"Jarvis\": \"Jervis Street\",\n",
    "           \"Pender\": \"Pender Street\",\n",
    "           \"Nanaimo\": \"Nanaimo Street\",\n",
    "           \"2nd\": \"2nd Avenue\",\n",
    "           \"Denmanstreet\": \"Denman Street\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_name(name, mapping):\n",
    "    unique = [\"108\", \"203\", \"216\", \"328\", \"701\", \"G101\"]\n",
    "    direction = [\"East\", \"West\"]\n",
    "\n",
    "    m = street_type_re.search(name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type in mapping:\n",
    "            name = name[:-len(street_type)] + mapping[street_type]\n",
    "        elif street_type == 'Vancouver':\n",
    "            name = name[:-len(street_type)].strip()\n",
    "            return update_name(name, mapping)\n",
    "        elif street_type in unique:\n",
    "            parts = name.split(\"#\")\n",
    "            name = parts[1] + \" \" +parts[0].strip()\n",
    "            return update_name(name, mapping)\n",
    "        elif street_type in direction:\n",
    "            parts = name.split(\" \")\n",
    "            name = parts[2] + \" \" +parts[0] + \" \" +parts[1]\n",
    "            return update_name(name, mapping)\n",
    "        elif street_type == \"E\":\n",
    "            parts = name.split(\" \")\n",
    "            name = \"East \"+ parts[0]+ \" Avenue\"\n",
    "        elif street_type == \"W\":\n",
    "            parts = name.split(\" \")\n",
    "            if len(parts) > 2:\n",
    "                name = parts[0]+ \" West \"+ parts[1]+ \" Avenue\"\n",
    "            elif len(parts) < 3:\n",
    "                name = \"West \"+ parts[0]\n",
    "\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, update_name(tag.attrib['v'], mapping))\n",
    "    osm_file.close()\n",
    "    return street_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA = schema.Schema\n",
    "\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=problemchars, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    if element.tag == 'node':\n",
    "        try:\n",
    "            for field in NODE_FIELDS:\n",
    "                node_attribs[field] = (element.attrib[field])\n",
    "            for tag in element.iter(\"tag\"):\n",
    "                tag_id = node_attribs[\"id\"]\n",
    "                tag_value = tag.attrib[\"v\"]\n",
    "                if is_street_name(tag):\n",
    "                    tag_value = update_name(tag_value, mapping)\n",
    "                tag_key = tag.attrib[\"k\"]\n",
    "                if problemchars.search(tag_key):\n",
    "                    break\n",
    "                if tag_key.find(\":\") == -1:\n",
    "                    tag_type = default_tag_type\n",
    "                else:\n",
    "                    tag_key = tag_key[tag_key.find(\":\")+1:]\n",
    "                    tag_type = tag_key[:tag_key.find(\":\")]\n",
    "                tags.append({'id':tag_id, 'key':tag_key, 'value':tag_value, 'type':tag_type})\n",
    "        except:\n",
    "            pass\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        try:\n",
    "            position = 0\n",
    "            for field in WAY_FIELDS:\n",
    "                way_attribs[field] = (element.attrib[field])\n",
    "            for member in element.iter(\"nd\"):\n",
    "                way_nodes.append({\"id\": way_attribs[\"id\"], \"node_id\": member.attrib[\"ref\"], \"position\": position})\n",
    "                position += 1\n",
    "            for tag in element.iter(\"tag\"):\n",
    "                tag_id = way_attribs[\"id\"]\n",
    "                tag_value = tag.attrib[\"v\"]\n",
    "                if is_street_name(tag):\n",
    "                    tag_value = update_name(tag_value, mapping)\n",
    "                tag_key = tag.attrib[\"k\"]\n",
    "                if problemchars.search(tag_key):\n",
    "                    break\n",
    "                if tag_key.find(\":\") == -1:\n",
    "                    tag_type = default_tag_type\n",
    "                else:\n",
    "                    tag_key = tag_key[tag_key.find(\":\")+1:]\n",
    "                    tag_type = tag_key[:tag_key.find(\":\")]\n",
    "                tags.append({'id':tag_id, 'key':tag_key, 'value':tag_value, 'type':tag_type})\n",
    "        except:\n",
    "            pass\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(nodes_path, 'w') as nodes_file, codecs.open(node_tags_path, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(ways_path, 'w') as ways_file, codecs.open(way_nodes_path, 'w') as way_nodes_file, \\\n",
    "         codecs.open(way_tags_path, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'iteritems'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-27811546d4cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocess_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosm_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-149-c38e54cbb7cd>\u001b[0m in \u001b[0;36mprocess_map\u001b[0;34m(file_in, validate)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mway_tags_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnicodeDictWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mway_tags_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWAY_TAGS_FIELDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mnodes_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mnode_tags_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mways_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/user/anaconda3/lib/python3.6/csv.py\u001b[0m in \u001b[0;36mwriteheader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwriteheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfieldnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfieldnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dict_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-147-e5bab4b96d86>\u001b[0m in \u001b[0;36mwriterow\u001b[0;34m(self, row)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         super(UnicodeDictWriter, self).writerow({\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         })\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'iteritems'"
     ]
    }
   ],
   "source": [
    "process_map(osm_path, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
